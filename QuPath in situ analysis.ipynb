{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c07de7e8",
   "metadata": {},
   "source": [
    "This code imports csv files containing detection analysis of in situ data from QuPath. \n",
    "It assumes you have used classifiers in QuPath to define each cell as positive or negative for each gene of interest. Data is structured as one QuPath project (and one csv output) per mouse, with multiple images per project.\n",
    "\n",
    "This code was adapted for use in Python from previous code written in R, available at https://github.com/SodenLab/Simon-et-al. Cursor AI coding software was used to convert the code from R to Python, and to assist with adding additional features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd60fc6c",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### Loading libraries and defining functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0aadfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import datetime\n",
    "import subprocess\n",
    "from collections import Counter\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ab7046",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### Defining functions for subsetting cells "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ee9863",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_cells(data, gene):\n",
    "    \"\"\"Return cells positive for a given gene (exact match, handles whitespace)\"\"\"\n",
    "    # Split classifications, strip whitespace, and check for exact gene match\n",
    "    return data[data['Classification'].apply(\n",
    "        lambda x: gene in [g.strip() for g in x.split(':')] if pd.notna(x) else False\n",
    "    )]\n",
    "\n",
    "def neg_cells(data, gene):\n",
    "    \"\"\"Return cells negative for a given gene (exact match, handles whitespace)\"\"\"\n",
    "    # Split classifications, strip whitespace, and check that gene is NOT in the list\n",
    "    return data[data['Classification'].apply(\n",
    "        lambda x: gene not in [g.strip() for g in x.split(':')] if pd.notna(x) else True\n",
    "    )]\n",
    "\n",
    "def posOR_cells(data, gene1, gene2):\n",
    "    \"\"\"Return cells positive for either of two genes (exact match, handles whitespace)\"\"\"\n",
    "    # Split classifications, strip whitespace, and check if either gene is in the list\n",
    "    return data[data['Classification'].apply(\n",
    "        lambda x: any(g.strip() in [gene1, gene2] for g in x.split(':')) if pd.notna(x) else False\n",
    "    )]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67ecdba",
   "metadata": {},
   "source": [
    "### Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997cb3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining some functions to check columns of CSVs\n",
    "def check_csv_consistency(filepath):\n",
    "    \"\"\"\n",
    "    Check if all CSV files have the same column names and order\n",
    "    \n",
    "    Parameters:\n",
    "    filepath: path to directory containing CSV files\n",
    "    \n",
    "    Returns:\n",
    "    dict with consistency information\n",
    "    \"\"\"\n",
    "    # Get list of all CSV files\n",
    "    csv_files = [f for f in os.listdir(filepath) if f.endswith('.csv')]\n",
    "    print(f\"Found {len(csv_files)} CSV files: {csv_files}\")\n",
    "    \n",
    "    if len(csv_files) == 0:\n",
    "        return {\"error\": \"No CSV files found\"}\n",
    "    \n",
    "    # Dictionary to store results\n",
    "    results = {\n",
    "        \"files_checked\": csv_files,\n",
    "        \"column_info\": {},\n",
    "        \"all_same_columns\": True,\n",
    "        \"all_same_order\": True,\n",
    "        \"column_differences\": [],\n",
    "        \"order_differences\": []\n",
    "    }\n",
    "    \n",
    "    # Read headers from all files\n",
    "    file_columns = {}\n",
    "    \n",
    "    for csv_file in csv_files:\n",
    "        try:\n",
    "            # Read just the first row to get column names\n",
    "            sample = pd.read_csv(os.path.join(filepath, csv_file), nrows=0)\n",
    "            file_columns[csv_file] = list(sample.columns)\n",
    "            results[\"column_info\"][csv_file] = {\n",
    "                \"num_columns\": len(sample.columns),\n",
    "                \"columns\": list(sample.columns)\n",
    "            }\n",
    "            print(f\"{csv_file}: {len(sample.columns)} columns\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {csv_file}: {e}\")\n",
    "            results[\"column_info\"][csv_file] = {\"error\": str(e)}\n",
    "    \n",
    "    # Check if all files have the same columns (regardless of order)\n",
    "    if len(file_columns) > 1:\n",
    "        # Get all unique column sets\n",
    "        column_sets = [set(cols) for cols in file_columns.values()]\n",
    "        first_set = column_sets[0]\n",
    "        \n",
    "        # Check if all sets are identical\n",
    "        for i, col_set in enumerate(column_sets[1:], 1):\n",
    "            if col_set != first_set:\n",
    "                results[\"all_same_columns\"] = False\n",
    "                file1 = csv_files[0]\n",
    "                file2 = csv_files[i]\n",
    "                \n",
    "                missing_in_file2 = first_set - col_set\n",
    "                extra_in_file2 = col_set - first_set\n",
    "                \n",
    "                results[\"column_differences\"].append({\n",
    "                    \"file1\": file1,\n",
    "                    \"file2\": file2,\n",
    "                    \"missing_in_file2\": list(missing_in_file2),\n",
    "                    \"extra_in_file2\": list(extra_in_file2)\n",
    "                })\n",
    "    \n",
    "    # Check if all files have the same column order\n",
    "    if len(file_columns) > 1:\n",
    "        first_order = list(file_columns.values())[0]\n",
    "        \n",
    "        for i, (filename, columns) in enumerate(list(file_columns.items())[1:], 1):\n",
    "            if columns != first_order:\n",
    "                results[\"all_same_order\"] = False\n",
    "                results[\"order_differences\"].append({\n",
    "                    \"reference_file\": csv_files[0],\n",
    "                    \"different_file\": filename,\n",
    "                    \"reference_order\": first_order,\n",
    "                    \"different_order\": columns\n",
    "                })\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b621af07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this check on your data to confirm that all files have the same column names\n",
    "filepath = './Data'\n",
    "consistency_results = check_csv_consistency(filepath)\n",
    "\n",
    "# Print summary\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"CONSISTENCY CHECK RESULTS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(f\"\\nFiles checked: {len(consistency_results['files_checked'])}\")\n",
    "print(f\"All files have same columns: {consistency_results['all_same_columns']}\")\n",
    "print(f\"All files have same column order: {consistency_results['all_same_order']}\")\n",
    "\n",
    "if not consistency_results['all_same_columns']:\n",
    "    print(f\"\\nCOLUMN DIFFERENCES FOUND:\")\n",
    "    for diff in consistency_results['column_differences']:\n",
    "        print(f\"\\nBetween {diff['file1']} and {diff['file2']}:\")\n",
    "        if diff['missing_in_file2']:\n",
    "            print(f\"  Missing in {diff['file2']}: {diff['missing_in_file2']}\")\n",
    "        if diff['extra_in_file2']:\n",
    "            print(f\"  Extra in {diff['file2']}: {diff['extra_in_file2']}\")\n",
    "\n",
    "if not consistency_results['all_same_order']:\n",
    "    print(f\"\\nCOLUMN ORDER DIFFERENCES FOUND:\")\n",
    "    for diff in consistency_results['order_differences']:\n",
    "        print(f\"\\n{diff['different_file']} has different order than {diff['reference_file']}\")\n",
    "        print(\"First 10 columns comparison:\")\n",
    "        ref_cols = diff['reference_order'][:10]\n",
    "        diff_cols = diff['different_order'][:10]\n",
    "        for i, (ref, diff_col) in enumerate(zip(ref_cols, diff_cols)):\n",
    "            match = \"✓\" if ref == diff_col else \"✗\"\n",
    "            print(f\"  {i+1:2d}: {ref:30} | {diff_col:30} {match}\")\n",
    "\n",
    "# Additional detailed analysis\n",
    "print(f\"\\n\" + \"=\"*50)\n",
    "print(\"DETAILED COLUMN ANALYSIS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Show column count summary\n",
    "column_counts = [info.get('num_columns', 0) for info in consistency_results['column_info'].values() if 'num_columns' in info]\n",
    "if column_counts:\n",
    "    print(f\"\\nColumn counts across files:\")\n",
    "    count_summary = Counter(column_counts)\n",
    "    for count, freq in sorted(count_summary.items()):\n",
    "        print(f\"  {count} columns: {freq} files\")\n",
    "    \n",
    "    if len(set(column_counts)) > 1:\n",
    "        print(f\"\\n⚠️  WARNING: Files have different numbers of columns!\")\n",
    "        for filename, info in consistency_results['column_info'].items():\n",
    "            if 'num_columns' in info:\n",
    "                print(f\"    {filename}: {info['num_columns']} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba27cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only run after you have verified that all files have the same column names.\n",
    "#Column names do not need to be in the same order, this will sort them and concatenate.\n",
    "\n",
    "filepath = './Data'\n",
    "\n",
    "# Get list of all CSV files in the directory\n",
    "csv_files = [f for f in os.listdir(filepath) if f.endswith('.csv')]\n",
    "print(f\"Found CSV files: {csv_files}\")\n",
    "\n",
    "# Extract mouseIDs from CSV filenames (removing .csv extension)\n",
    "mouseIDs = sorted(list(set([os.path.splitext(f)[0] for f in csv_files])))\n",
    "print(f\"Found mouseIDs: {mouseIDs}\")\n",
    "\n",
    "# Read all CSV files into a list first\n",
    "print(\"Reading CSV files...\")\n",
    "dataframes = []\n",
    "for csv_file in csv_files:\n",
    "    print(f\"Reading {csv_file}...\")\n",
    "    # Read CSV with columns 4 and 5 as strings to avoid mixed type warning\n",
    "    data = pd.read_csv(os.path.join(filepath, csv_file), \n",
    "                   dtype={4: str, 5: str},\n",
    "                   na_filter=False) \n",
    "    # Add mouseID column from filename (without .csv extension)\n",
    "    data['mouseID'] = os.path.splitext(csv_file)[0]\n",
    "    # Add NumGenes column before concatenating\n",
    "    data['NumGenes'] = data['Classification'].apply(lambda x: len(x.split(':')) if x else 0)\n",
    "    \n",
    "    # Sort columns alphabetically to ensure consistent order\n",
    "    data = data.reindex(sorted(data.columns), axis=1)\n",
    "    \n",
    "    dataframes.append(data)\n",
    "\n",
    "# Concatenate all dataframes at once\n",
    "all_data = pd.concat(dataframes, ignore_index=True)\n",
    "print(f\"Loaded {len(csv_files)} CSV files with {len(all_data)} total rows\")\n",
    "\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036d9d13",
   "metadata": {},
   "source": [
    "### Importing Annotation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fdfcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing QuPath annotation files so we have the area of each subregion. Used to calculate normalized cell counts.\n",
    "\n",
    "# Directory containing CSV files\n",
    "annotations_filepath = r'./Annotations'\n",
    "\n",
    "# Get list of all CSV files in the directory\n",
    "csv_files = [f for f in os.listdir(annotations_filepath) if f.endswith('.csv')]\n",
    "print(f\"Found CSV files: {csv_files}\")\n",
    "\n",
    "# Read all CSV files into a list first\n",
    "print(\"Reading CSV files...\")\n",
    "dataframes = []\n",
    "all_columns = set()\n",
    "\n",
    "# First pass: collect all unique column names (excluding \"Num\" columns)\n",
    "for csv_file in csv_files:\n",
    "    print(f\"Scanning columns in {csv_file}...\")\n",
    "    data = pd.read_csv(os.path.join(annotations_filepath, csv_file))\n",
    "    \n",
    "    # Filter out columns that start with \"Num\"\n",
    "    filtered_columns = [col for col in data.columns if not col.startswith('Num')]\n",
    "    all_columns.update(filtered_columns)\n",
    "    \n",
    "    print(f\"  {len(data.columns)} total columns, {len(filtered_columns)} after excluding 'Num' columns\")\n",
    "\n",
    "# Convert to sorted list for consistent ordering\n",
    "all_columns = sorted(list(all_columns))\n",
    "# Add our custom columns\n",
    "all_columns.extend(['mouseID', 'source_file'])\n",
    "print(f\"\\nTotal unique columns across all files (excluding 'Num' columns): {len(all_columns)}\")\n",
    "\n",
    "# Second pass: read files and standardize columns\n",
    "for csv_file in csv_files:\n",
    "    print(f\"Reading {csv_file}...\")\n",
    "    # Read CSV file\n",
    "    data = pd.read_csv(os.path.join(annotations_filepath, csv_file))\n",
    "    \n",
    "    # Remove columns that start with \"Num\"\n",
    "    data = data[[col for col in data.columns if not col.startswith('Num')]]\n",
    "    \n",
    "    # Extract mouseID from filename\n",
    "    mouseID = csv_file.replace(' annotations.csv', '')\n",
    "    print(f\"  Extracted mouseID: {mouseID}\")\n",
    "    \n",
    "    # Add our custom columns\n",
    "    data['mouseID'] = mouseID\n",
    "    data['source_file'] = csv_file\n",
    "    \n",
    "    # Add any missing columns with NaN values\n",
    "    for col in all_columns:\n",
    "        if col not in data.columns:\n",
    "            data[col] = pd.NA\n",
    "            print(f\"    Added missing column: {col}\")\n",
    "    \n",
    "    # Reorder columns to match the standard order\n",
    "    data = data[all_columns]\n",
    "    \n",
    "    dataframes.append(data)\n",
    "\n",
    "# Concatenate all dataframes at once\n",
    "print(f\"\\nConcatenating {len(dataframes)} dataframes...\")\n",
    "annotations = pd.concat(dataframes, ignore_index=True)\n",
    "print(f\"Loaded {len(csv_files)} CSV files with {len(annotations)} total rows\")\n",
    "\n",
    "# Display basic info about the combined dataframe\n",
    "print(f\"\\nAnnotations dataframe shape: {annotations.shape}\")\n",
    "print(f\"Columns: {len(annotations.columns)}\")\n",
    "print(f\"Unique mouseIDs: {annotations['mouseID'].unique()}\")\n",
    "annotations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fc0857",
   "metadata": {},
   "source": [
    "### Making Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7973f518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolates all cells that express a given gene (cannon_gene) and then plots expression of up to 3 genes in those cells\n",
    "# Cannon_OR and _AND genes are optional, and can be used to isolate cells that express either or both of the two genes.\n",
    "\n",
    "# Plot settings\n",
    "cannon_gene = 'Nts'\n",
    "cannon_OR_gene = 'none'\n",
    "cannon_AND_gene = 'none'\n",
    "sub_gene1 = 'Nts'\n",
    "sub_gene2 = 'Slc32a1'\n",
    "sub_gene3 = 'Slc17a6'\n",
    "\n",
    "# Colors for different genes\n",
    "color1 = 'darkcyan'\n",
    "color2 = 'darkorange'\n",
    "color3 = 'darkmagenta'\n",
    "\n",
    "# Create Plots subfolder within the main filepath\n",
    "plots_dir = os.path.join(filepath, 'Plots')\n",
    "os.makedirs(plots_dir, exist_ok=True)\n",
    "\n",
    "# Get unique mouseIDs from the mouseID column\n",
    "mouseIDs = sorted(all_data['mouseID'].unique())\n",
    "print(f\"Found mouseIDs: {mouseIDs}\")\n",
    "\n",
    "# Function to create a single subplot\n",
    "def create_subplot(ax, data, secname):\n",
    "    \"\"\"Create a subplot for a single section\"\"\"\n",
    "    # Get cells positive for each gene\n",
    "    sub_cells1 = pos_cells(data=data, gene=sub_gene1) if sub_gene1 != 'none' else data\n",
    "    sub_cells2 = pos_cells(data=data, gene=sub_gene2) if sub_gene2 != 'none' else None\n",
    "    sub_cells3 = pos_cells(data=data, gene=sub_gene3) if sub_gene3 != 'none' else None\n",
    "    \n",
    "    # Plot points for each gene\n",
    "    ax.scatter(sub_cells1['Centroid X µm'], sub_cells1['Centroid Y µm'], \n",
    "              color=color1, alpha=0.5, s=25, label=sub_gene1)\n",
    "    \n",
    "    if sub_cells2 is not None:\n",
    "        ax.scatter(sub_cells2['Centroid X µm'], sub_cells2['Centroid Y µm'], \n",
    "                  color=color2, alpha=0.5, s=25, label=sub_gene2)\n",
    "    \n",
    "    if sub_cells3 is not None:\n",
    "        ax.scatter(sub_cells3['Centroid X µm'], sub_cells3['Centroid Y µm'], \n",
    "                  color=color3, alpha=0.5, s=25, label=sub_gene3)\n",
    "    \n",
    "    # Set plot properties\n",
    "    ax.set_xlim(0, 2500)\n",
    "    ax.set_ylim(2500, 0)\n",
    "    ax.set_title(secname, fontsize=10)\n",
    "    ax.axis('equal')\n",
    "    ax.grid(False)\n",
    "    ax.legend(loc='lower center', fontsize=8)\n",
    "\n",
    "# Process each mouse\n",
    "for mouse in mouseIDs:\n",
    "    # Filter data for this mouse\n",
    "    mouseonly = all_data[all_data['mouseID'] == mouse]\n",
    "    \n",
    "    # Get unique section numbers for this mouse from the Image column\n",
    "    sections = sorted(set([int(image.split('Image_')[1][:2]) for image in mouseonly['Image'].unique()]))\n",
    "    print(f\"Mouse {mouse} has sections: {sections}\")\n",
    "\n",
    "    \n",
    "    # Calculate grid dimensions\n",
    "    n_sections = len(sections)\n",
    "    n_cols = min(3, n_sections)  # Max 3 columns\n",
    "    n_rows = (n_sections + n_cols - 1) // n_cols  # Ceiling division\n",
    "    \n",
    "    # Create figure for this mouse\n",
    "    fig = plt.figure(figsize=(5*n_cols, 5*n_rows))\n",
    "    fig.suptitle(f'Mouse {mouse}', fontsize=16)\n",
    "    \n",
    "    # Create subplots for each section\n",
    "    for i, section in enumerate(sections, 1):\n",
    "        # Filter data for this section using Image column\n",
    "        section_str = f\"{section:02d}\"  # Convert to zero-padded 2-digit string\n",
    "        seconly = mouseonly[mouseonly['Image'].str.contains(f'Image_{section_str}')]\n",
    "        \n",
    "        # Generate section name\n",
    "        if cannon_gene == 'none':\n",
    "            secname = f'Section {section}'\n",
    "            cannon_cells = seconly\n",
    "        else:\n",
    "            if cannon_OR_gene == 'none':\n",
    "                secname = f'Section {section}\\n{cannon_gene}+'\n",
    "                cannon_cells = pos_cells(data=seconly, gene=cannon_gene)\n",
    "            else:\n",
    "                secname = f'Section {section}\\n{cannon_gene}+ or {cannon_OR_gene}+'\n",
    "                cannon_cells = posOR_cells(data=seconly, gene1=cannon_gene, gene2=cannon_OR_gene)\n",
    "            \n",
    "            if cannon_AND_gene != 'none':\n",
    "                secname = f'Section {section}\\n{cannon_gene}+ or {cannon_OR_gene}+ and {cannon_AND_gene}+'\n",
    "                cannon_cells = pos_cells(data=cannon_cells, gene=cannon_AND_gene)\n",
    "        \n",
    "        # Create subplot\n",
    "        ax = fig.add_subplot(n_rows, n_cols, i)\n",
    "        create_subplot(ax, cannon_cells, secname)\n",
    "    \n",
    "    # Adjust layout and save\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(plots_dir, f'{mouse}_all_sections.pdf'))\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba96efbb",
   "metadata": {},
   "source": [
    "### Plot one gene with shading based on intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75f3eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plots all cells positive for a single gene, with shading based on fluorescence intensity.\n",
    "# Color scaling set to 10-90th percentile for each mouse to prevent outliers from dominating the plot, can be adjusted below\n",
    "\n",
    "gene = 'Nts'\n",
    "\n",
    "# Create Plots subfolder within the main filepath\n",
    "plots_dir = os.path.join(filepath, 'Plots')\n",
    "os.makedirs(plots_dir, exist_ok=True)\n",
    "\n",
    "# Get unique mouseIDs from the mouseID column\n",
    "mouseIDs = sorted(all_data['mouseID'].unique())\n",
    "print(f\"Found mouseIDs: {mouseIDs}\")\n",
    "\n",
    "# Function to create a single subplot\n",
    "def create_intensity_subplot(ax, cells, secname, vmin, vmax):\n",
    "    \"\"\"Create an intensity subplot for a single section\"\"\"\n",
    "    scatter = ax.scatter(cells['Centroid X µm'], cells['Centroid Y µm'],\n",
    "                        c=cells[f'Nucleus: {gene} mean'],  # Using raw intensity values\n",
    "                        cmap='Blues',\n",
    "                        vmin=vmin, vmax=vmax,\n",
    "                        s=25)\n",
    "    \n",
    "    # Set plot properties\n",
    "    ax.set_xlim(0, 2500)\n",
    "    ax.set_ylim(2500, 0)\n",
    "    ax.set_title(secname, fontsize=10)\n",
    "    ax.axis('equal')\n",
    "    ax.grid(False)\n",
    "    \n",
    "    return scatter\n",
    "\n",
    "# Process each mouse\n",
    "for mouse in mouseIDs:\n",
    "    # Filter data for this mouse\n",
    "    mouseonly = all_data[all_data['mouseID'] == mouse]\n",
    "    \n",
    "    # Calculate intensity limits for this mouse only\n",
    "    mouse_intensities = mouseonly[mouseonly['Classification'].str.contains(gene, na=False)][f'Cell: {gene} mean']\n",
    "    vmin = mouse_intensities.quantile(0.1)  # 10th percentile\n",
    "    vmax = mouse_intensities.quantile(0.9)  # 90th percentile\n",
    "    print(f\"Mouse {mouse} intensity range: {vmin:.2f} to {vmax:.2f}\")\n",
    "    \n",
    "    # Get unique section numbers for this mouse from the Image column\n",
    "    sections = sorted(set([int(image.split('Image_')[1][:2]) for image in mouseonly['Image'].unique()]))\n",
    "    print(f\"Mouse {mouse} has sections: {sections}\")\n",
    "    \n",
    "    # Calculate grid dimensions\n",
    "    n_sections = len(sections)\n",
    "    n_cols = min(3, n_sections)\n",
    "    n_rows = (n_sections + n_cols - 1) // n_cols\n",
    "    \n",
    "    # Create figure for this mouse\n",
    "    fig = plt.figure(figsize=(5*n_cols, 5*n_rows))\n",
    "    fig.suptitle(f'Mouse {mouse} - {gene} Raw Intensity', fontsize=16)\n",
    "    \n",
    "    # Create subplots for each section\n",
    "    for i, section in enumerate(sections, 1):\n",
    "        # Filter data for this section using Image column\n",
    "        section_str = f\"{section:02d}\"  # Convert to zero-padded 2-digit string\n",
    "        seconly = mouseonly[mouseonly['Image'].str.contains(f'Image_{section_str}')]\n",
    "        secname = f'Section {section}'\n",
    "        cells = pos_cells(data=seconly, gene=gene)\n",
    "        \n",
    "        # Create subplot\n",
    "        ax = fig.add_subplot(n_rows, n_cols, i)\n",
    "        scatter = create_intensity_subplot(ax, cells, secname, vmin, vmax)\n",
    "        \n",
    "        # Add colorbar to the first subplot only\n",
    "        if i == 1:\n",
    "            plt.colorbar(scatter, ax=ax, label=f'{gene} Raw Intensity')\n",
    "    \n",
    "    # Adjust layout and save\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(plots_dir, f'{mouse}_{gene}_raw_intensity_all_sections.pdf'), \n",
    "                bbox_inches='tight', dpi=300)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11209eb",
   "metadata": {},
   "source": [
    "### Rostral-Caudal Cell Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f950baa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Counts cells positive for each gene in each region (defined in QuPath), separated by section.\n",
    "\n",
    "#pre_subset_gene is optional, and can be used to isolate only cells positive for a given gene.\n",
    "#pre_subset_not_genes are optional, and can be used to count cells negative for a given gene(s) (i.e. Nts cells with no Vglut2 or Vgat)\n",
    "\n",
    "pre_subset_gene = 'none'\n",
    "pre_subset_not_gene1 = 'none'\n",
    "pre_subset_not_gene2 = 'none'\n",
    "genelist = sorted(set(\n",
    "    gene.strip() \n",
    "    for classification in all_data['Classification'].dropna().unique()\n",
    "    for gene in classification.split(':')\n",
    "    if gene.strip()  # This will exclude empty strings and whitespace-only entries\n",
    "))\n",
    "\n",
    "# Get unique overlapping regions \n",
    "all_regions = set()\n",
    "for regions_str in all_data['Overlapping Regions'].dropna().unique():\n",
    "    regions = [r.strip() for r in regions_str.split(';') if r.strip() and r.strip() != 'DAPI cells']\n",
    "    all_regions.update(regions)\n",
    "\n",
    "overlapping_regions = sorted(list(all_regions))\n",
    "print(f\"Found overlapping regions: {overlapping_regions}\")\n",
    "\n",
    "# Create main output directory\n",
    "main_plots_dir = os.path.join(filepath, 'Counts_by_Region')\n",
    "os.makedirs(main_plots_dir, exist_ok=True)\n",
    "\n",
    "# Initialize dictionaries to store data for all regions\n",
    "all_raw_data = {}\n",
    "all_normalized_data = {}\n",
    "\n",
    "# Process each overlapping region separately\n",
    "for region in overlapping_regions:\n",
    "    print(f\"\\n=== Processing region: {region} ===\")\n",
    "    \n",
    "    # Filter data to only include cells in this overlapping region\n",
    "    region_data = all_data[all_data['Overlapping Regions'].apply(lambda x: region in [r.strip() for r in str(x).split(';')] if pd.notna(x) else False)]\n",
    "    print(f\"Found {len(region_data)} cells in {region}\")\n",
    "    \n",
    "    if len(region_data) == 0:\n",
    "        print(f\"No data found for region {region}, skipping...\")\n",
    "        continue\n",
    "    \n",
    "    # Initialize lists to store data for this region\n",
    "    region_raw_rows = []\n",
    "    region_normalized_rows = []\n",
    "    \n",
    "    for mouse in mouseIDs:\n",
    "        # Filter data for specific mouse and region\n",
    "        mouseonly = region_data[region_data['mouseID'] == mouse]\n",
    "        \n",
    "        if len(mouseonly) == 0:\n",
    "            print(f\"No data for mouse {mouse} in region {region}\")\n",
    "            continue\n",
    "        \n",
    "        # Get unique section numbers for this mouse from the Image column\n",
    "        sections = sorted(set([int(image.split('Image_')[1][:2]) for image in mouseonly['Image'].unique()]))\n",
    "        print(f\"Mouse {mouse} in {region} has sections: {sections}\")\n",
    "        \n",
    "        # Pre-subset by gene if specified\n",
    "        if pre_subset_gene != 'none':\n",
    "            mouseonly = pos_cells(data=mouseonly, gene=pre_subset_gene)\n",
    "            print(f\"Pre-subsetting data to {pre_subset_gene}+ cells\")\n",
    "\n",
    "        if pre_subset_not_gene1 != 'none':\n",
    "            mouseonly = neg_cells(data=mouseonly, gene=pre_subset_not_gene1)\n",
    "            print(f\"Pre-subsetting data to {pre_subset_not_gene1}- cells\")\n",
    "\n",
    "        if pre_subset_not_gene2 != 'none':\n",
    "            mouseonly = neg_cells(data=mouseonly, gene=pre_subset_not_gene2)\n",
    "            print(f\"Pre-subsetting data to {pre_subset_not_gene2}- cells\")\n",
    "        \n",
    "        for section in sections:\n",
    "            # Filter data for specific section using Image column\n",
    "            section_str = f\"{section:02d}\"  # Convert to zero-padded 2-digit string\n",
    "            seconly = mouseonly[mouseonly['Image'].str.contains(f'Image_{section_str}')]\n",
    "            \n",
    "            # Find the region area for this section in annotations (if available)\n",
    "            section_annotations = annotations[annotations['Image'].str.contains(f'Image_{section_str}')]\n",
    "            region_annotation = section_annotations[section_annotations['Name'] == region]\n",
    "            \n",
    "            if len(region_annotation) > 0:\n",
    "                region_area = region_annotation['Area µm^2'].iloc[0]  # Get the area in square microns\n",
    "                print(f\"  Section {section}: {region} area = {region_area:.2f} µm²\")\n",
    "            else:\n",
    "                print(f\"  Warning: No {region} annotation found for section {section}, using PAG area as fallback\")\n",
    "                # Fallback to PAG area if region annotation not found\n",
    "                pag_annotation = section_annotations[section_annotations['Name'] == 'PAG']\n",
    "                if len(pag_annotation) > 0:\n",
    "                    region_area = pag_annotation['Area µm^2'].iloc[0]\n",
    "                else:\n",
    "                    region_area = None\n",
    "            \n",
    "            # Count cells for each gene\n",
    "            for gene in genelist:\n",
    "                sub_cells = pos_cells(data=seconly, gene=gene)\n",
    "                cell_count = len(sub_cells)\n",
    "                \n",
    "                # Add raw count row\n",
    "                region_raw_rows.append({\n",
    "                    'Gene': gene,\n",
    "                    'Section': section,\n",
    "                    'MouseID': mouse,\n",
    "                    'Count': cell_count\n",
    "                })\n",
    "                \n",
    "                # Calculate normalized count (cells per square micron)\n",
    "                if region_area is not None and region_area > 0:\n",
    "                    normalized_count = cell_count / region_area\n",
    "                else:\n",
    "                    normalized_count = None\n",
    "                \n",
    "                # Add normalized count row\n",
    "                region_normalized_rows.append({\n",
    "                    'Gene': gene,\n",
    "                    'Section': section,\n",
    "                    'MouseID': mouse,\n",
    "                    'Normalized_Count': normalized_count,\n",
    "                    'Area_um2': region_area\n",
    "                })\n",
    "    \n",
    "    # Convert to DataFrames and store in dictionaries\n",
    "    if region_raw_rows:\n",
    "        raw_df = pd.DataFrame(region_raw_rows)\n",
    "        # Pivot to have mice as columns, with MultiIndex for Gene and Section\n",
    "        raw_pivot = raw_df.pivot_table(\n",
    "            index=['Gene', 'Section'], \n",
    "            columns='MouseID', \n",
    "            values='Count', \n",
    "            fill_value=0\n",
    "        )\n",
    "        all_raw_data[region] = raw_pivot\n",
    "        \n",
    "        normalized_df = pd.DataFrame(region_normalized_rows)\n",
    "        # Pivot normalized data - mice as columns, genes and sections as rows\n",
    "        normalized_pivot = normalized_df.pivot_table(\n",
    "            index=['Gene', 'Section'], \n",
    "            columns='MouseID', \n",
    "            values='Normalized_Count', \n",
    "            fill_value=None\n",
    "        )\n",
    "        all_normalized_data[region] = normalized_pivot\n",
    "        \n",
    "        print(f\"Processed {len(raw_df)} records for {region}\")\n",
    "\n",
    "# Save all raw counts to one Excel file\n",
    "raw_counts_file = os.path.join(main_plots_dir, 'All_Regions_Raw_Counts.xlsx')\n",
    "with pd.ExcelWriter(raw_counts_file, engine='openpyxl') as writer:\n",
    "    for region, data in all_raw_data.items():\n",
    "        # Clean sheet name \n",
    "        sheet_name = region.replace(' ', '_').replace('/', '_')[:31]  # Excel limit is 31 chars\n",
    "        data.to_excel(writer, sheet_name=sheet_name)\n",
    "        print(f\"Added raw counts for {region} to Excel file\")\n",
    "\n",
    "print(f\"Saved all raw counts to: {raw_counts_file}\")\n",
    "\n",
    "# Save all normalized counts to one Excel file\n",
    "normalized_counts_file = os.path.join(main_plots_dir, 'All_Regions_Normalized_Counts.xlsx')\n",
    "with pd.ExcelWriter(normalized_counts_file, engine='openpyxl') as writer:\n",
    "    for region, data in all_normalized_data.items():\n",
    "        # Clean sheet name \n",
    "        sheet_name = region.replace(' ', '_').replace('/', '_')[:31]  # Excel limit is 31 chars\n",
    "        data.to_excel(writer, sheet_name=sheet_name)\n",
    "        print(f\"Added normalized counts for {region} to Excel file\")\n",
    "\n",
    "print(f\"Saved all normalized counts to: {normalized_counts_file}\")\n",
    "\n",
    "print(f\"\\nCompleted processing all overlapping regions. Results saved in: {main_plots_dir}\")\n",
    "print(f\"Created {len(all_raw_data)} region tabs in each Excel file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f7c103",
   "metadata": {},
   "source": [
    "### Dorsal-Ventral Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18387ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find minimum Y coordinate for normalization\n",
    "def min_y(data):\n",
    "    \"\"\"Find the minimum Y coordinate in a dataset\"\"\"\n",
    "    if len(data) == 0:\n",
    "        return 0\n",
    "    return data['Centroid Y µm'].min()\n",
    "    \n",
    "num_sections = max(\n",
    "    int(image.split('Image_')[1][:2]) \n",
    "    for image in all_data['Image'].unique()\n",
    ")\n",
    "min_y_vec = []\n",
    "\n",
    "for mouse in mouseIDs:\n",
    "    mouseonly = all_data[all_data['mouseID'] == mouse]\n",
    "    \n",
    "    for section in range(1, num_sections + 1):\n",
    "        section_str = f\"{section:02d}\"  # Convert to zero-padded 2-digit string\n",
    "        seconly = mouseonly[mouseonly['Image'].str.contains(f'Image_{section_str}')]\n",
    "        min_y_val = min_y(seconly)\n",
    "        min_y_vec.extend([min_y_val] * len(seconly))\n",
    "\n",
    "# Add minimum Y values and adjusted Y coordinates to data\n",
    "adj_data_dv = all_data.copy()\n",
    "adj_data_dv['min_y_vec'] = min_y_vec\n",
    "adj_data_dv['YMinAdj'] = adj_data_dv['Centroid Y µm'] - adj_data_dv['min_y_vec']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1af030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates a histogram of the dorsal-ventral distribution of cells positive for a given gene.\n",
    "\n",
    "cannon_gene = 'Nts'\n",
    "cannon_OR_gene = 'none'\n",
    "cannon_AND_gene = 'none'\n",
    "\n",
    "color = 'darkcyan'\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "plots_dir = os.path.join(filepath, 'DV Histograms')\n",
    "os.makedirs(plots_dir, exist_ok=True)\n",
    "\n",
    "# Process data for all mice\n",
    "all_sub_cells = pd.DataFrame()\n",
    "\n",
    "for mouse in mouseIDs:\n",
    "    mouseonly = adj_data_dv[adj_data_dv['mouseID'] == mouse]\n",
    "    \n",
    "    if cannon_OR_gene == 'none':\n",
    "        cannon_cells = pos_cells(data=mouseonly, gene=cannon_gene)\n",
    "    else:\n",
    "        cannon_cells = posOR_cells(data=mouseonly, gene1=cannon_gene, gene2=cannon_OR_gene)\n",
    "    \n",
    "    if cannon_AND_gene != 'none':\n",
    "        cannon_cells = pos_cells(data=cannon_cells, gene=cannon_AND_gene)\n",
    "    \n",
    "\n",
    "# Create histogram plot for dorsal-ventral distribution\n",
    "plt.figure(figsize=(6, 8))  \n",
    "\n",
    "# For smoothed density plot\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "if len(cannon_cells) > 0:\n",
    "    # Create density plot\n",
    "    density = gaussian_kde(cannon_cells['YMinAdj'])\n",
    "    \n",
    "    # Determine reasonable range based on data\n",
    "    y_min = cannon_cells['YMinAdj'].min()\n",
    "    y_max = cannon_cells['YMinAdj'].max()\n",
    "    \n",
    "    # Add some padding to the range\n",
    "    y_range = y_max - y_min\n",
    "    plot_min = max(0, y_min - y_range * 0.1)  \n",
    "    plot_max = y_max + y_range * 0.1\n",
    "    \n",
    "    ys = np.linspace(plot_min, plot_max, 200)\n",
    "    density_values = density(ys)\n",
    "    \n",
    "    # Plot with Y coordinates on Y-axis and density on X-axis\n",
    "    plt.fill_betweenx(ys, density_values, alpha=0.8, color=color)\n",
    "    \n",
    "    plt.ylim(plot_min, plot_max)\n",
    "    \n",
    "    # Set x-limit for density (you may need to adjust this based on your data)\n",
    "    max_density = density_values.max()\n",
    "    plt.xlim(0, max_density * 1.1)\n",
    "    \n",
    "    plt.ylabel('Dorsal-Ventral Position (Y adjusted, µm)', fontsize=12)\n",
    "    plt.xlabel('Density', fontsize=12)\n",
    "else:\n",
    "    plt.text(0.5, 0.5, 'No data available', ha='center', va='center', \n",
    "             transform=plt.gca().transAxes, fontsize=12)\n",
    "    plt.ylim(0, 1000)\n",
    "    plt.xlim(0, 0.001)\n",
    "\n",
    "# Invert Y-axis so 0 is at the top (dorsal) and increases downward (ventral)\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "plt.title(f\"Dorsal-Ventral Distribution: {cannon_gene}_OR_{cannon_OR_gene}_AND_{cannon_AND_gene}\")\n",
    "plt.grid(False)\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "# Save plot\n",
    "plt.savefig(os.path.join(plots_dir, f\"DV_{cannon_gene}_OR_{cannon_OR_gene}_AND_{cannon_AND_gene}.pdf\"))\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "print(f\"Saved dorsal-ventral histogram to: {plots_dir}\")\n",
    "print(f\"Data range: Y adjusted from {cannon_cells['YMinAdj'].min():.1f} to {cannon_cells['YMinAdj'].max():.1f} µm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c620985a",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### Euler Plots for gene overlap visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4553a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euler_cells_dynamic(data, genes, pos_neg_pattern):\n",
    "    \"\"\"\n",
    "    Calculate cell counts for any number of genes (2-4)\n",
    "    \n",
    "    Parameters:\n",
    "    data: DataFrame\n",
    "    genes: list of gene names\n",
    "    pos_neg_pattern: list of 'pos' or 'neg' values, same length as genes\n",
    "    \"\"\"\n",
    "    result = data.copy()\n",
    "    \n",
    "    # Handle empty input DataFrame\n",
    "    if len(result) == 0:\n",
    "        return 0\n",
    "    \n",
    "    for i, gene in enumerate(genes):\n",
    "        pattern = pos_neg_pattern[i]\n",
    "        if pattern == 'pos':\n",
    "            # Filter to include only cells positive for this gene\n",
    "            result = result[result['Classification'].apply(\n",
    "                lambda x: gene in [g.strip() for g in x.split(':')] if pd.notna(x) and x.strip() != '' else False\n",
    "            )]\n",
    "        else:  # pattern == 'neg'\n",
    "            # Use exact match with whitespace handling\n",
    "            result = result[result['Classification'].apply(\n",
    "                lambda x: gene not in [g.strip() for g in x.split(':')] if pd.notna(x) and x.strip() != '' else True\n",
    "            )]\n",
    "        \n",
    "        # If result is empty after filtering, return 0 immediately to avoid further column access issues\n",
    "        if len(result) == 0:\n",
    "            return 0\n",
    "    \n",
    "    return len(result)\n",
    "\n",
    "def euler_values_dynamic(data, genes):\n",
    "    \"\"\"\n",
    "    Calculate all possible combinations for Euler diagrams\n",
    "    Works with 2-4 genes\n",
    "    \n",
    "    Parameters:\n",
    "    data: DataFrame\n",
    "    genes: list of gene names\n",
    "    \"\"\"\n",
    "    import itertools\n",
    "    \n",
    "    n_genes = len(genes)\n",
    "    if not 2 <= n_genes <= 4:\n",
    "        raise ValueError(\"Number of genes must be between 2 and 4\")\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Generate all possible combinations of pos/neg patterns\n",
    "    # For each position, we need to determine if we want that gene to be positive or negative\n",
    "    for r in range(1, n_genes + 1):  # r is the number of 'pos' genes we want\n",
    "        for pos_positions in itertools.combinations(range(n_genes), r):\n",
    "            pattern = ['neg'] * n_genes  # Start with all 'neg'\n",
    "            for pos in pos_positions:  # Set selected positions to 'pos'\n",
    "                pattern[pos] = 'pos'\n",
    "            \n",
    "            count = euler_cells_dynamic(data, genes, pattern)\n",
    "            results.append(count)\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd93bc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings for Euler plots\n",
    "cannon_gene = 'none'\n",
    "cannon_OR_gene = 'none'\n",
    "# Define sub_genes as a list - can be 2, 3, or 4 genes\n",
    "sub_genes = ['Nts','Slc32a1','Slc17a6']  \n",
    "colors = ['darkcyan', 'darkorange', 'darkmagenta', 'darkgreen']  \n",
    "shape = 'ellipse'  # can be 'ellipse' or 'circle'\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "plots_dir = os.path.join(filepath, 'Euler Plots')\n",
    "os.makedirs(plots_dir, exist_ok=True)\n",
    "\n",
    "# Initialize DataFrame for cell counts - columns will depend on number of genes\n",
    "def get_column_names(n_genes):\n",
    "    \"\"\"Generate column names for n genes\"\"\"\n",
    "    import itertools\n",
    "    letters = ['A', 'B', 'C', 'D'][:n_genes]\n",
    "    columns = []\n",
    "    # Add single gene columns\n",
    "    for r in range(1, n_genes + 1):\n",
    "        for combo in itertools.combinations(letters, r):\n",
    "            columns.append('&'.join(combo))\n",
    "    return columns\n",
    "\n",
    "n_genes = len(sub_genes)\n",
    "if not 2 <= n_genes <= 4:\n",
    "    raise ValueError(\"Number of sub_genes must be 2, 3, or 4\")\n",
    "\n",
    "cell_counts = pd.DataFrame(columns=get_column_names(n_genes))\n",
    "\n",
    "for mouse in mouseIDs:\n",
    "    mouseonly = all_data[all_data['mouseID'] == mouse]\n",
    "    \n",
    "    # Apply canonical gene filters if specified\n",
    "    if cannon_gene == 'none':\n",
    "        cannon_cells = mouseonly\n",
    "    else:\n",
    "        if cannon_OR_gene == 'none':\n",
    "            cannon_cells = pos_cells(data=mouseonly, gene=cannon_gene)\n",
    "        else:\n",
    "            cannon_cells = posOR_cells(data=mouseonly, gene1=cannon_gene, gene2=cannon_OR_gene)\n",
    "    \n",
    "    # Calculate cell counts for Euler diagram using dynamic function\n",
    "    counts = euler_values_dynamic(cannon_cells, sub_genes)\n",
    "    cell_counts.loc[mouse] = counts\n",
    "\n",
    "# Sum counts across all mice\n",
    "totals = cell_counts.sum()\n",
    "\n",
    "# Create unique output paths with timestamp to avoid file conflicts\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_base = f\"{'_'.join(sub_genes)}_{timestamp}\"\n",
    "output_path = os.path.join(plots_dir, f'{output_base}_euler.pdf').replace('\\\\', '/')\n",
    "png_path = os.path.join(plots_dir, f'{output_base}_euler.png').replace('\\\\', '/')\n",
    "\n",
    "# Create color string for R\n",
    "color_string = ', '.join(f'\"{c}\"' for c in colors[:n_genes])\n",
    "\n",
    "# Create R script with dynamic number of genes\n",
    "r_script_parts = [\n",
    "    \"library(eulerr)\\n\\n\",\n",
    "    \"# Create the counts\\n\",\n",
    "    \"counts <- c(\\n\"\n",
    "]\n",
    "\n",
    "# Add counts dynamically based on number of genes\n",
    "print(\"Column mappings for Euler plot:\")\n",
    "print(f\"Sub-genes: {sub_genes}\")\n",
    "for col, val in totals.items():\n",
    "    # Convert column names to R-compatible names \n",
    "    r_name = col\n",
    "    \n",
    "    # Create letter to gene mapping\n",
    "    letter_to_gene = dict(zip(['A', 'B', 'C', 'D'], sub_genes))\n",
    "    \n",
    "    # Split by '&' to handle each part separately\n",
    "    parts = r_name.split('&')\n",
    "    gene_parts = []\n",
    "    \n",
    "    for part in parts:\n",
    "        if part in letter_to_gene:\n",
    "            gene_parts.append(letter_to_gene[part])\n",
    "        else:\n",
    "            gene_parts.append(part)  # fallback if something goes wrong\n",
    "    \n",
    "    r_name = '&'.join(gene_parts)\n",
    "    \n",
    "    print(f\"  {col} -> {r_name} = {int(val)}\")\n",
    "    r_script_parts.append(f\"    `{r_name}` = {int(val)},\\n\")\n",
    "\n",
    "r_script_parts[-1] = r_script_parts[-1].rstrip(',\\n') + '\\n'  # Remove last comma\n",
    "\n",
    "# Add the rest of the R script\n",
    "r_script_parts.extend([\n",
    "    \")\\n\\n\",\n",
    "    f\"# Create euler diagram\\n\",\n",
    "    f\"fit <- euler(counts, shape = \\\"{shape}\\\")\\n\\n\",\n",
    "    f\"# Save as PDF\\n\",\n",
    "    f\"pdf(\\\"{output_path}\\\", width=8, height=8)\\n\",\n",
    "    f\"plot(fit,\\n\",\n",
    "    f\"     fills = c({color_string}),\\n\",\n",
    "    f\"     alpha = 0.4,\\n\",\n",
    "    f\"     quantities = TRUE,\\n\",\n",
    "    f\"     main = \\\"Gene Expression Overlap\\\")\\n\",\n",
    "    f\"dev.off()\\n\\n\",\n",
    "    f\"# Save as PNG for notebook display\\n\",\n",
    "    f\"png(\\\"{png_path}\\\", width=800, height=800)\\n\",\n",
    "    f\"plot(fit,\\n\",\n",
    "    f\"     fills = c({color_string}),\\n\",\n",
    "    f\"     alpha = 0.4,\\n\",\n",
    "    f\"     quantities = TRUE,\\n\",\n",
    "    f\"     main = \\\"Gene Expression Overlap\\\")\\n\",\n",
    "    f\"dev.off()\\n\"\n",
    "])\n",
    "\n",
    "r_script = ''.join(r_script_parts)\n",
    "\n",
    "# Write R script to file with timestamp\n",
    "script_path = os.path.join(plots_dir, f'euler_script_{timestamp}.R')\n",
    "with open(script_path, 'w') as f:\n",
    "    f.write(r_script)\n",
    "\n",
    "print(f\"\\nR script content preview:\")\n",
    "print(\"counts <- c(\")\n",
    "for col, val in totals.items():\n",
    "    letter_to_gene = dict(zip(['A', 'B', 'C', 'D'], sub_genes))\n",
    "    parts = col.split('&')\n",
    "    gene_parts = [letter_to_gene.get(part, part) for part in parts]\n",
    "    r_name = '&'.join(gene_parts)\n",
    "    print(f\"    `{r_name}` = {int(val)},\")\n",
    "print(\")\")\n",
    "\n",
    "# Execute R script with error capture\n",
    "r_path = \"C:/Program Files/R/R-4.1.2/bin/x64/Rscript.exe\"\n",
    "try:\n",
    "    result = subprocess.run([r_path, script_path], \n",
    "                          check=True, \n",
    "                          capture_output=True, \n",
    "                          text=True)\n",
    "    print(f\"\\nR script executed successfully!\")\n",
    "    print(f\"Files created: {output_base}_euler.pdf and {output_base}_euler.png\")\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"R script failed with return code {e.returncode}\")\n",
    "    print(f\"STDERR: {e.stderr}\")\n",
    "    raise\n",
    "\n",
    "# Display the plot \n",
    "from IPython.display import Image, display\n",
    "display(Image(png_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f770bc0",
   "metadata": {},
   "source": [
    "Calculating Nts cells expressing any other peptide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc6b75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cells_expressing_any(data, gene_list):\n",
    "    \"\"\"Return cells expressing any gene from a list of genes (exact match, handles whitespace)\"\"\"\n",
    "    # Split classifications, strip whitespace, and check if any gene from the list is present\n",
    "    return data[data['Classification'].apply(\n",
    "        lambda x: any(g.strip() in gene_list for g in x.split(':')) if pd.notna(x) else False\n",
    "    )]\n",
    "\n",
    "\n",
    "nts_cells = pos_cells(data=all_data, gene='Nts')\n",
    "anypep = cells_expressing_any(data=nts_cells, gene_list=['Adcyap1', 'Cck', 'Pdyn', 'Penk', 'Tac1'])\n",
    "\n",
    "print(\"number of Nts cells:\", len(nts_cells))\n",
    "print(\"number of Nts cells expressing any other peptide:\", len(anypep))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ac6926",
   "metadata": {},
   "source": [
    "Calculating number of Nts Cells positive for X number of peptide genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed19b3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings \n",
    "primary_gene = 'Nts'  # Gene to subset by (e.g., 'Nts')\n",
    "coexpression_genes = ['Adcyap1', 'Cck', 'Pdyn', 'Penk', 'Tac1']  # List of genes to check co-expression\n",
    "#coexpression_genes = ['Ntsr1']\n",
    "\n",
    "# Optional: filter by region first (set to None to use all data)\n",
    "target_region = None  \n",
    "\n",
    "# Helper function to count genes expressed in a cell\n",
    "def count_coexpressed_genes(classification, gene_list):\n",
    "    \"\"\"Count how many genes from gene_list are expressed in a cell\"\"\"\n",
    "    if pd.isna(classification):\n",
    "        return 0\n",
    "    cell_genes = [g.strip() for g in classification.split(':')]\n",
    "    return sum(1 for gene in gene_list if gene in cell_genes)\n",
    "\n",
    "def is_gene_positive(classification, gene):\n",
    "    \"\"\"Check if a cell expresses a specific gene\"\"\"\n",
    "    if pd.isna(classification):\n",
    "        return False\n",
    "    cell_genes = [g.strip() for g in classification.split(':')]\n",
    "    return gene in cell_genes\n",
    "\n",
    "\n",
    "# Start with all data or filter by region\n",
    "if target_region is not None:\n",
    "    # Use exact region matching \n",
    "    working_data = all_data[all_data['Overlapping Regions'].apply(\n",
    "        lambda x: target_region in [r.strip() for r in str(x).split(';')] if pd.notna(x) else False\n",
    "    )]\n",
    "    print(f\"Filtered to {target_region}: {len(working_data)} cells\")\n",
    "else:\n",
    "    working_data = all_data.copy()\n",
    "    print(f\"Using all data: {len(working_data)} cells\")\n",
    "\n",
    "# Subset to primary gene positive cells\n",
    "primary_positive = pos_cells(working_data, primary_gene)\n",
    "print(f\"Found {len(primary_positive)} {primary_gene}+ cells\")\n",
    "\n",
    "# Calculate co-expression statistics per mouse\n",
    "coexpression_results = []\n",
    "distribution_results = []\n",
    "\n",
    "for mouse in mouseIDs:\n",
    "    mouse_data = primary_positive[primary_positive['mouseID'] == mouse]\n",
    "    total_cells = len(mouse_data)\n",
    "    \n",
    "    if total_cells == 0:\n",
    "        print(f\"No {primary_gene}+ cells found for mouse {mouse}\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\nMouse {mouse}: {total_cells} {primary_gene}+ cells\")\n",
    "    \n",
    "    # --- Part 1: Percent co-expressing each gene ---\n",
    "    coexp_row = {'MouseID': mouse, 'Total_Primary_Positive': total_cells}\n",
    "    \n",
    "    for gene in coexpression_genes:\n",
    "        # Count cells positive for this gene\n",
    "        positive_count = mouse_data['Classification'].apply(\n",
    "            lambda x: is_gene_positive(x, gene)\n",
    "        ).sum()\n",
    "        \n",
    "        percent_positive = (positive_count / total_cells) * 100\n",
    "        coexp_row[f'{gene}_count'] = positive_count\n",
    "        coexp_row[f'{gene}_percent'] = percent_positive\n",
    "        \n",
    "        print(f\"  {gene}: {positive_count} cells ({percent_positive:.1f}%)\")\n",
    "    \n",
    "    coexpression_results.append(coexp_row)\n",
    "    \n",
    "    # --- Part 2: Distribution of number of co-expressed genes ---\n",
    "    # Count how many of the coexpression_genes each cell expresses\n",
    "    mouse_data = mouse_data.copy()\n",
    "    mouse_data['num_coexpressed'] = mouse_data['Classification'].apply(\n",
    "        lambda x: count_coexpressed_genes(x, coexpression_genes)\n",
    "    )\n",
    "    \n",
    "    # Calculate distribution (0 to max possible genes)\n",
    "    max_genes = len(coexpression_genes)\n",
    "    dist_row = {'MouseID': mouse, 'Total_Primary_Positive': total_cells}\n",
    "    \n",
    "    print(f\"  Co-expression distribution:\")\n",
    "    for n in range(0, max_genes + 1):\n",
    "        count_n = (mouse_data['num_coexpressed'] == n).sum()\n",
    "        percent_n = (count_n / total_cells) * 100\n",
    "        dist_row[f'{n}_genes_count'] = count_n\n",
    "        dist_row[f'{n}_genes_percent'] = percent_n\n",
    "        print(f\"    {n} genes: {count_n} cells ({percent_n:.1f}%)\")\n",
    "    \n",
    "    distribution_results.append(dist_row)\n",
    "\n",
    "# Create summary DataFrames\n",
    "coexpression_df = pd.DataFrame(coexpression_results)\n",
    "distribution_df = pd.DataFrame(distribution_results)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CO-EXPRESSION SUMMARY (% of primary+ cells expressing each gene)\")\n",
    "print(\"=\"*60)\n",
    "display(coexpression_df)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DISTRIBUTION SUMMARY (% of primary+ cells co-expressing N genes)\")\n",
    "print(\"=\"*60)\n",
    "display(distribution_df)\n",
    "\n",
    "# Save to Excel\n",
    "output_dir = os.path.join(filepath, 'Coexpression_Analysis')\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "region_suffix = f\"_{target_region}\" if target_region else \"_all_regions\"\n",
    "output_file = os.path.join(output_dir, f'{primary_gene}_coexpression{region_suffix}.xlsx')\n",
    "\n",
    "with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
    "    coexpression_df.to_excel(writer, sheet_name='Gene_Coexpression', index=False)\n",
    "    distribution_df.to_excel(writer, sheet_name='Num_Genes_Distribution', index=False)\n",
    "\n",
    "print(f\"\\nResults saved to: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21be0453",
   "metadata": {},
   "source": [
    "Calculating intensity of Nts staining across subdivisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27333502",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_gene = 'Nts'  \n",
    "\n",
    "# The intensity column name pattern is typically \"Nucleus: {gene} mean\"\n",
    "# Adjust if your column naming is different\n",
    "intensity_column = f'Nucleus: {target_gene} mean'\n",
    "\n",
    "# Helper function for exact region matching\n",
    "def has_exact_region(regions_str, target_region):\n",
    "    \"\"\"Check if a cell is in exactly the specified region (not substring match)\"\"\"\n",
    "    if pd.isna(regions_str):\n",
    "        return False\n",
    "    regions = [r.strip() for r in regions_str.split(';')]\n",
    "    return target_region in regions\n",
    "\n",
    "# Get all unique regions \n",
    "all_regions = set()\n",
    "for regions_str in all_data['Overlapping Regions'].dropna().unique():\n",
    "    regions = [r.strip() for r in regions_str.split(';') if r.strip() and r.strip() != 'DAPI cells']\n",
    "    all_regions.update(regions)\n",
    "\n",
    "overlapping_regions = sorted(list(all_regions))\n",
    "print(f\"Found regions: {overlapping_regions}\")\n",
    "\n",
    "# Verify intensity column exists\n",
    "if intensity_column not in all_data.columns:\n",
    "    print(f\"\\nWARNING: Column '{intensity_column}' not found!\")\n",
    "    print(\"Available columns containing 'mean':\")\n",
    "    mean_cols = [col for col in all_data.columns if 'mean' in col.lower()]\n",
    "    for col in mean_cols[:20]:  # Show first 20\n",
    "        print(f\"  - {col}\")\n",
    "    # Try to suggest the correct column\n",
    "    gene_cols = [col for col in mean_cols if target_gene.lower() in col.lower()]\n",
    "    if gene_cols:\n",
    "        print(f\"\\nColumns matching '{target_gene}':\")\n",
    "        for col in gene_cols:\n",
    "            print(f\"  - {col}\")\n",
    "else:\n",
    "    print(f\"Using intensity column: {intensity_column}\")\n",
    "\n",
    "# Filter to gene-positive cells\n",
    "gene_positive_cells = pos_cells(all_data, target_gene)\n",
    "print(f\"\\nFound {len(gene_positive_cells)} {target_gene}+ cells total\")\n",
    "\n",
    "# Calculate mean intensity per region per mouse\n",
    "intensity_results = []\n",
    "\n",
    "for region in overlapping_regions:\n",
    "    print(f\"\\n=== Region: {region} ===\")\n",
    "    \n",
    "    # Filter gene-positive cells to this EXACT region\n",
    "    region_cells = gene_positive_cells[gene_positive_cells['Overlapping Regions'].apply(\n",
    "        lambda x: has_exact_region(x, region)\n",
    "    )]\n",
    "    \n",
    "    print(f\"  {len(region_cells)} {target_gene}+ cells in {region}\")\n",
    "    \n",
    "    if len(region_cells) == 0:\n",
    "        continue\n",
    "    \n",
    "    for mouse in mouseIDs:\n",
    "        mouse_cells = region_cells[region_cells['mouseID'] == mouse]\n",
    "        n_cells = len(mouse_cells)\n",
    "        \n",
    "        if n_cells == 0:\n",
    "            continue\n",
    "        \n",
    "        # Calculate mean intensity\n",
    "        if intensity_column in mouse_cells.columns:\n",
    "            mean_intensity = mouse_cells[intensity_column].mean()\n",
    "            std_intensity = mouse_cells[intensity_column].std()\n",
    "            sem_intensity = std_intensity / np.sqrt(n_cells) if n_cells > 1 else np.nan\n",
    "        else:\n",
    "            mean_intensity = np.nan\n",
    "            std_intensity = np.nan\n",
    "            sem_intensity = np.nan\n",
    "        \n",
    "        intensity_results.append({\n",
    "            'Region': region,\n",
    "            'MouseID': mouse,\n",
    "            'N_Cells': n_cells,\n",
    "            'Mean_Intensity': mean_intensity,\n",
    "            'Std_Intensity': std_intensity,\n",
    "            'SEM_Intensity': sem_intensity\n",
    "        })\n",
    "        \n",
    "        print(f\"    Mouse {mouse}: {n_cells} cells, Mean = {mean_intensity:.2f} ± {sem_intensity:.2f} (SEM)\")\n",
    "\n",
    "# Create summary DataFrame\n",
    "intensity_df = pd.DataFrame(intensity_results)\n",
    "\n",
    "# Pivot for easier viewing - mice as columns, regions as rows\n",
    "if len(intensity_df) > 0:\n",
    "    pivot_mean = intensity_df.pivot_table(\n",
    "        index='Region', \n",
    "        columns='MouseID', \n",
    "        values='Mean_Intensity'\n",
    "    )\n",
    "    \n",
    "    pivot_n = intensity_df.pivot_table(\n",
    "        index='Region', \n",
    "        columns='MouseID', \n",
    "        values='N_Cells'\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"MEAN {target_gene} INTENSITY BY REGION AND MOUSE\")\n",
    "    print(\"=\"*60)\n",
    "    display(pivot_mean)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"CELL COUNTS BY REGION AND MOUSE\")\n",
    "    print(\"=\"*60)\n",
    "    display(pivot_n)\n",
    "\n",
    "# Save to Excel\n",
    "output_dir = os.path.join(filepath, 'Intensity_Analysis')\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "output_file = os.path.join(output_dir, f'{target_gene}_intensity_by_region.xlsx')\n",
    "\n",
    "with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
    "    # Full data (long format)\n",
    "    intensity_df.to_excel(writer, sheet_name='Full_Data', index=False)\n",
    "    \n",
    "    # Pivoted views\n",
    "    if len(intensity_df) > 0:\n",
    "        pivot_mean.to_excel(writer, sheet_name='Mean_Intensity_Pivot')\n",
    "        pivot_n.to_excel(writer, sheet_name='Cell_Counts_Pivot')\n",
    "\n",
    "print(f\"\\nResults saved to: {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
